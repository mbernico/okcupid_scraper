{
 "metadata": {
  "name": "",
  "signature": "sha256:3bedd198239b6145ab84352e29bc492ed9065d67edea32e8e4f385343cbb5218"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cookielib\n",
      "import urllib2\n",
      "import urllib\n",
      "import time\n",
      "from BeautifulSoup import BeautifulSoup\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def setup_connection(username = None, password = None):\n",
      "    # setup credentials and url requests\n",
      "    # cookie storage\n",
      "    cj = cookielib.CookieJar()\n",
      "    opener = urllib2.build_opener(\n",
      "    urllib2.HTTPCookieProcessor(cj),\n",
      "    urllib2.HTTPRedirectHandler\n",
      "    )\n",
      "    # Useragent\n",
      "    opener.addheaders.append(('User-agent','Mozilla/4.0'))\n",
      "\n",
      "    url = 'http://www.okcupid.com/login'\n",
      "    login_data = urllib.urlencode({\n",
      "    'username':username,\n",
      "    'password':password,\n",
      "    })\n",
      "\n",
      "    req = urllib2.Request(url,login_data)\n",
      "    resp = opener.open(req)\n",
      "    return opener"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#once a set of usernames is identified, we will add them to our collection\n",
      "def process_names(userNameTags):\n",
      "    userNames = [str(tag.contents[0]) for tag in userNameTags]\n",
      "    \n",
      "    return set(userNames)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scrape_OKC(iters=1, opener = None):\n",
      "    userSet = set()\n",
      "\n",
      "    wideOpenSearch = 'http://www.okcupid.com/match?filter1=0,63&filter2=76,4095&filter3=2,25,60&filter4=5,31536000&filter5=1,1&locid=0&timekey=1&matchOrderBy=SPECIAL_BLEND&custom_search=0&fromWhoOnline=0&mygender=f&update_prefs=1&sort_type=0&sa=1&using_saved_search=&count=18'\n",
      "    i = 0\n",
      "    while i < iters:\n",
      "        try:\n",
      "            req = urllib2.Request(wideOpenSearch)\n",
      "            resp = opener.open(req)\n",
      "            soup = BeautifulSoup(resp)\n",
      "\n",
      "            userNameTags = soup.findAll('a', attrs={'class': 'name'})\n",
      "            userSet.update(process_names(userNameTags))\n",
      "            #print \"Request %d finished.\" % i\n",
      "        except:\n",
      "            #print \"ERROR ON %d\"%i\n",
      "            continue\n",
      "\n",
      "        i = i+1\n",
      "        time.sleep(3) # don't pound the OKCupid servers\n",
      "    return userSet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#parse page for each user in userSet\n",
      "def parse_user(userSet):\n",
      "    userInfo = []\n",
      "    for user in userSet:\n",
      "        \n",
      "        userURL = r\"http://www.okcupid.com/profile/\" + user + \"?cf=regular\"\n",
      "        \n",
      "        try:\n",
      "            req = urllib2.Request(userURL)\n",
      "            resp = opener.open(req)\n",
      "            soup = BeautifulSoup(resp)\n",
      "\n",
      "            #get info per user, from the soup\n",
      "            age = soup.find('span', attrs={\"id\":\"ajax_age\"}).text\n",
      "            location = soup.find('span', attrs={\"id\":\"ajax_location\"}).text\n",
      "            gender = soup.find('span', attrs={\"class\":\"ajax_gender\"}).text\n",
      "            desired_gender = soup.find('li', attrs={\"id\":\"ajax_gentation\"}).text\n",
      "            desired_ages = soup.find('li', attrs={\"id\":\"ajax_ages\"}).text\n",
      "            desired_ages = re.sub('&ndash;', ':', desired_ages)\n",
      "            desired_distance = soup.find('li', attrs={\"id\":\"ajax_near\"}).text\n",
      "            desired_single = soup.find('li', attrs={\"id\":\"ajax_single\"}).text\n",
      "            desired_relationship_status = soup.find('li', attrs={\"id\":\"ajax_lookingfor\"}).text\n",
      "            orientation = soup.find('dd', attrs={\"id\":\"ajax_orientation\"}).text\n",
      "            ethnicity = soup.find('dd', attrs={\"id\":\"ajax_ethnicities\"}).text\n",
      "            height = soup.find('dd', attrs={\"id\":\"ajax_height\"}).text\n",
      "            body_type = soup.find('dd', attrs={\"id\":\"ajax_bodytype\"}).text\n",
      "            diet = soup.find('dd', attrs={\"id\":\"ajax_diet\"}).text\n",
      "            smokes = soup.find('dd', attrs={\"id\":\"ajax_smoking\"}).text\n",
      "            drinks = soup.find('dd', attrs={\"id\":\"ajax_drinking\"}).text\n",
      "            drugs = soup.find('dd', attrs={\"id\":\"ajax_drugs\"}).text\n",
      "            religion = soup.find('dd', attrs={\"id\":\"ajax_religion\"}).text\n",
      "            education = soup.find('dd', attrs={\"id\":\"ajax_education\"}).text\n",
      "            job = soup.find('dd', attrs={\"id\":\"ajax_job\"}).text\n",
      "            income = soup.find('dd', attrs={\"id\":\"ajax_income\"}).text\n",
      "            relationship_status = soup.find('dd', attrs={\"id\":\"ajax_status\"}).text\n",
      "            relationship_type = soup.find('dd', attrs={\"id\":\"ajax_monogamous\"}).text\n",
      "            children = soup.find('dd', attrs={\"id\":\"ajax_children\"}).text\n",
      "            pets = soup.find('dd', attrs={\"id\":\"ajax_pets\"}).text\n",
      "            languages = soup.find('dd', attrs={\"id\":\"ajax_languages\"}).text\n",
      "            userImage = soup.find('img')['src']\n",
      "\n",
      "            userDict = {'userName': user, 'age':age, 'location':location, 'gender': gender, 'desired_gender': desired_gender,\n",
      "                        'desired_ages':desired_ages, 'desired_distance':desired_distance, 'desired_single':desired_single,\n",
      "                        'desired_relationship_status':desired_relationship_status, 'orientation':orientation, \n",
      "                        'ethnicity':ethnicity, 'height':height, 'body_type':body_type, 'diet':diet, 'smokes':smokes,\n",
      "                        'drinks':drinks, 'drugs':drugs, 'religion':religion, 'education':education, 'job':job, 'income':income, \n",
      "                        'relationship_status':relationship_status, 'relationship_type':relationship_type, 'children':children,\n",
      "                        'pets':pets, 'languages':languages, 'userImage':userImage}\n",
      "\n",
      "            userInfo.append(userDict)\n",
      "            time.sleep(1) # don't pound the OKCupid servers\n",
      "\n",
      "            \n",
      "        except:\n",
      "            #print \"ERROR ON %s\" % user\n",
      "            continue\n",
      "    return userInfo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_images(df):\n",
      "    df = df[-df['userImage'].isnull()]\n",
      "    userImages = df['userImage']\n",
      "    userNames = df['userName']\n",
      "    \n",
      "    for name, image in zip (userNames, userImages):\n",
      "        urllib.urlretrieve(image, './images/'+ name +\".jpg\")\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#main stuff here\n",
      "username = '<username>'\n",
      "password = '<password>'\n",
      "\n",
      "opener = setup_connection(username = username, password = password)\n",
      "userSet = scrape_OKC(iters=1, opener=opener)  #scrapes OKC for usernames iter times, each time it gets 10 non unique users\n",
      "userInfo = parse_user(userSet) #gets info on each unique username\n",
      "userDataFrame = pd.DataFrame(userInfo) #move data into a dataframe\n",
      "get_images(userDataFrame) #gets images for each username\n",
      "userDataFrame.to_json(\"OKC_scrape.json\") #writes out the DF\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}